# BPR&D API Configuration Status v3.0

**Last Updated:** 2026-02-14

---

## Summary

| Agent | Platform | Current Model | Latest Available | Status |
|-------|----------|---------------|------------------|--------|
| Grok | xAI | grok-3 | grok-4-1-fast-reasoning | ‚úÖ **OPERATIONAL** |
| Claude | Anthropic | claude-opus-4-5 | claude-opus-4-6 | ‚úÖ **OPERATIONAL** |
| Abacus | Abacus.AI | abacus-deep-agent | 50+ unified models | ‚úÖ **CONFIGURED** |
| Gemini | Google AI | gemini-3-pro-preview | gemini-3-pro-preview | ‚úÖ **OPERATIONAL** |

**All 4 platforms are now operational!**

---

## Platform 1: xAI (Grok) - SuperGrok Subscription

**Status:** ‚úÖ OPERATIONAL
**API Endpoint:** `https://api.x.ai/v1/chat/completions`
**Auth:** Bearer token
**Current Model:** `grok-3`
**Knowledge Cutoff:** November 2024

### Available Models

#### Grok 4 Series (Latest - Recommended)
- **`grok-4-1-fast-reasoning`** - Frontier model for agentic tool calling with reasoning (2M context) ‚≠ê **RECOMMENDED**
- **`grok-4-1-fast-non-reasoning`** - Fast variant without reasoning (2M context)
- **`grok-4-1-fast`** - Alias for grok-4-1-fast-reasoning
- **`grok-4-1-fast-latest`** - Always points to latest Grok 4.1

#### Grok 3 Series (Current)
- **`grok-3`** - Current flagship (currently configured)
- **`grok-3-fast`** - Faster variant
- **`grok-3-mini`** - Smaller, efficient model
- **`grok-3-mini-fast`** - Fastest mini variant

#### Specialized Models
- **`grok-code-fast-1`** - Optimized for coding tasks (256K context)
- **Grok Imagine API** - Image generation (separate endpoint)

**Upgrade Recommendation:** Migrate to `grok-4-1-fast-reasoning` for improved agentic performance and 2M context window.

---

## Platform 2: Anthropic (Claude) - Claude Pro Subscription

**Status:** ‚úÖ OPERATIONAL
**API Endpoint:** `https://api.anthropic.com/v1/messages`
**Auth:** x-api-key header
**API Version:** 2023-06-01
**Current Model:** `claude-opus-4-5`
**Knowledge Cutoff:** January 2025

### Available Models

#### Claude 4.6 Series (Latest)
- **`claude-opus-4-6`** - Most capable model ‚≠ê **RECOMMENDED**

#### Claude 4.5 Series (Stable)
- **`claude-opus-4-5`** - Previous flagship (currently configured)
- **`claude-sonnet-4-5-20250929`** - Fast, intelligent for most tasks
- **`claude-haiku-4-5-20251001`** - Fastest, most cost-effective

### Use Case Guide
- **Complex reasoning, long documents:** Opus 4.6
- **General-purpose, fast responses:** Sonnet 4.5
- **High-volume, quick tasks:** Haiku 4.5

**Upgrade Recommendation:** Migrate to `claude-opus-4-6` for latest capabilities.

---

## Platform 3: Google AI (Gemini) - Google AI Pro Subscription

**Status:** ‚úÖ OPERATIONAL (Upgraded 2026-02-14)
**API Endpoint:** Via Google AI Studio / Vertex AI
**Target Model:** `gemini-3-pro-preview`
**Legacy Key:** Available for Jules/Codebuff coding platform integration

### Available Models

#### Gemini 3 Series (Latest - Recommended)
- **`gemini-3-pro-preview`** - Reasoning-first model for complex agentic workflows ‚≠ê **RECOMMENDED**
  - Features: Adaptive thinking, 1M token context, integrated grounding
- **`gemini-3-flash-preview`** - Best for complex multimodal understanding
  - Features: Strong coding, state-of-the-art reasoning
- **`gemini-3-pro-image-preview`** - Image generation

#### Gemini 2.5 Series (Production/Stable)
- **`gemini-2.5-pro-preview-05-06`** - Code and function calling improvements
- **`gemini-2.5-flash-preview-04-17`** - Price-performance optimized
- **`gemini-2.5-flash-lite`** - High-volume, cost-sensitive

#### Specialized Models
- **Gemini Live API** - Native audio models
- **Computer Use** - Available in Gemini 3 Pro/Flash

#### ‚ö†Ô∏è DEPRECATED (Shut down March 31, 2026)
- All Gemini 2.0 models (Flash, Flash-Lite, Image Gen)
- All Gemini 1.0 and 1.5 models (already return 404)

**Context Windows:** Up to 1M tokens (Gemini 3)

---

## Platform 4: Abacus.AI - Abacus Pro Subscription

**Status:** ‚úÖ CONFIGURED (SDK ready, needs testing)
**Client:** `_agents/abacus/client.py`
**Platform:** https://abacus.ai/
**Deep Agent:** https://deepagent.abacus.ai/
**RouteLLM:** https://routellm-apis.abacus.ai/

### Unified LLM Access (15+ Models)

Abacus.AI provides **unified API access to ALL top models**:

- **`claude-sonnet-4.5`** - Anthropic Sonnet 4.5
- **`claude-opus-4.6`** - Anthropic Opus 4.6
- **`gpt-5.2`** - OpenAI GPT-5.2
- **`gpt-5.2-thinking`** - Extended reasoning
- **`gpt-5.2-codex`** - Code optimized
- **`gpt-5.2-pro`** - Pro tier
- **`o3`** - OpenAI o3 reasoning
- **`gpt-image`** - Image generation
- **`gemini-3.0-pro`** - Google Gemini 3.0 Pro
- **`grok-4.1`** - xAI Grok 4.1
- **`qwen-3`** - Alibaba Qwen 3
- **`qwen-3-coder`** - Coding optimized
- **`llama-4`** - Meta Llama 4

### Deep Agent (Automatic Routing) ‚≠ê
- **`abacus-deep-agent`** - Auto-routes to best LLM for task
- Intelligent model selection

### Image & Video (40+ Models)
- **`sora-2`** - OpenAI Sora 2 video
- **`veo-3`** - Google Veo-3 video
- **`flux-ultra-pro`** - Image generation
- **`grok-imagine`** - xAI image gen
- **`nano-banana-pro`**, **`kling-2.6`**, **`motion-control`**, and 30+ more

### Configuration
- Environment: `ABACUS_PRIMARY_KEY`, `ABACUS_BACKUP_KEY`
- SDK: `pip install abacusai python-dotenv`
- Client: Already configured in `_agents/abacus/client.py`

---

## Model Selection Guide for BPR&D Workflows

### By Use Case

| Use Case | Primary Model | Alternative | Platform |
|----------|---------------|-------------|----------|
| **Chief/Executive Decisions** | `grok-4-1-fast-reasoning` | `grok-3` | xAI |
| **Strategic Analysis** | `claude-opus-4-6` | `claude-sonnet-4.5` | Anthropic |
| **Code Generation** | `grok-code-fast-1` | `qwen-3-coder` (Abacus) | xAI / Abacus |
| **Fast Coding Tasks** | `claude-sonnet-4.5` | `gemini-3-flash-preview` | Anthropic / Google |
| **Complex Multimodal** | `gemini-3-pro-preview` | `gemini-3-flash-preview` | Google |
| **Adaptive Routing** | `abacus-deep-agent` | - | Abacus.AI |
| **High-Volume Tasks** | `claude-haiku-4.5` | `grok-3-mini-fast` | Anthropic / xAI |
| **Image Generation** | `grok-imagine` | `flux-ultra-pro` (Abacus) | xAI / Abacus |
| **Video Generation** | `sora-2` (Abacus) | `veo-3` (Abacus) | Abacus.AI |

### By Context Window Size

| Need | Model | Context | Platform |
|------|-------|---------|----------|
| **Massive (2M tokens)** | `grok-4-1-fast-reasoning` | 2M | xAI |
| **Large (1M tokens)** | `gemini-3-pro-preview` | 1M | Google |
| **Coding (256K tokens)** | `grok-code-fast-1` | 256K | xAI |
| **Standard** | `claude-opus-4-6` | Standard | Anthropic |

---

## Orchestrator Requirements

Once all APIs are configured, the orchestrator needs:
1. ‚úÖ API Client Classes for each platform
2. ‚úÖ Context Loader for profiles and active.md files
3. ‚úÖ Conversation Logger for real-time output
4. History Storage for past conversations
5. Handoff Manager for task delegation

---

## Immediate Actions

1. [x] Install abacusai Python SDK and test Abacus access (Configured in `_agents/abacus/client.py`)
2. [x] Upgrade Gemini API to paid tier (Completed 2026-02-14)
3. [ ] Test Abacus.AI SDK with `abacus-deep-agent` for automatic routing
4. [ ] Upgrade Grok to `grok-4-1-fast-reasoning` for better agentic performance
5. [ ] Upgrade Claude to `claude-opus-4-6` for latest capabilities
6. [ ] Test Gemini `gemini-3-pro-preview` or `gemini-3-flash-preview`
7. [ ] Research Jules/Codebuff legacy key for Gemini coding integration
8. [ ] Build orchestrator with all 4 working APIs

---

## Platform Summary

**Total Models Available:** 50+ models across all platforms

| Platform | Models Available | Status |
|----------|-----------------|--------|
| **xAI (Grok)** | ~10 (text + image) | ‚úÖ OPERATIONAL |
| **Anthropic (Claude)** | 3 current models | ‚úÖ OPERATIONAL |
| **Google AI (Gemini)** | ~8 active models | ‚úÖ OPERATIONAL |
| **Abacus.AI** | 15+ LLMs + 40+ image/video | ‚úÖ CONFIGURED |

---

## Notes

- **All 4 platforms are now operational!** üéâ
- Grok, Claude, and Gemini can collaborate via API
- Abacus provides unified access to all major models including GPT-5.2, o3, and more
- Team consolidated from 6 to 4 agents in February 2026
- Abacus inherits both Deep Agent and ChatLLM API keys
- Full team automation ready with all APIs configured

*v3.0 -- Updated February 2026 with complete model lists and Gemini operational status*

---

## Security & Environment Configuration

**Note:** All API keys have been removed from this file for security.
Please refer to `.env.example` for the required environment variables.

To configure your environment:
1. Copy `.env.example` to `.env`
2. Fill in the actual API keys in the `.env` file

**Required Environment Variables:**
- `XAI_API_KEY` or `GROK_API_KEY` - xAI Grok access
- `ANTHROPIC_API_KEY` - Claude access
- `GOOGLE_AI_API_KEY` or `GEMINI_API_KEY` - Gemini access
- `ABACUS_PRIMARY_KEY` - Abacus.AI primary key
- `ABACUS_BACKUP_KEY` - Abacus.AI backup key (optional)
- `JULES_LEGACY_KEY` - Jules/Codebuff key (optional)

---

## Additional Resources

### xAI (Grok)
- Documentation: https://docs.x.ai/developers/models
- API Console: https://x.ai/api
- Release Notes: https://docs.x.ai/developers/release-notes

### Anthropic (Claude)
- API Documentation: https://docs.anthropic.com/
- Model Information: In-product documentation

### Google AI (Gemini)
- AI Studio: https://ai.google.dev/
- Model Docs: https://ai.google.dev/gemini-api/docs/models
- Vertex AI: https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models

### Abacus.AI
- Platform: https://abacus.ai/
- API Reference: https://abacus.ai/help/api
- Deep Agent: https://deepagent.abacus.ai/
- RouteLLM: https://routellm-apis.abacus.ai/
